{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Unidad 7: Web Scraping</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.03001,
     "end_time": "2020-11-10T13:18:37.840723",
     "exception": false,
     "start_time": "2020-11-10T13:18:37.810713",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Introducción\n",
    "En esta lección revisaremos el proceso de **Web Scraping**. El **Web Scraping**, también conocido como raspado de páginas web, es un proceso automatizado que permite extraer información de páginas web y almacenarla en un formato estructurado para su posterior análisis. Esta técnica se utiliza comúnmente para recopilar grandes cantidades de datos de manera eficiente y automatizada, y se utiliza en diversas aplicaciones como la monitorización de precios, análisis de mercado, investigación de la competencia, entre otras.\n",
    "\n",
    "Básicamente, el web scraping implica el uso de software programado, como bots, crawlers o spiders, para rastrear uno o varios sitios web y extraer automáticamente la información, los contenidos y otros datos que contienen. El proceso es comparable al copiado y pegado, pero se realiza de manera automatizada y a gran escala.La mayoría de los datos extraídos mediante el web scraping son no estructurados, es decir, en formato HTML, y necesitan ser transformados en datos estructurados para su uso posterior en aplicaciones. Esto se puede lograr mediante la conversión de los datos extraídos en una hoja de cálculo o una base de datos, permitiendo así el análisis y la toma de decisiones basada en datos.\n",
    "\n",
    "Entre las aplicaciones más comunes del web scraping se encuentra la monitorización de precios en línea, que utiliza bots para extraer información sobre precios de diferentes sitios web, permitiendo así a las empresas comparar precios y ofrecer productos y servicios competitivos. Otras aplicaciones incluyen la investigación de la competencia, análisis de mercado, detección de fraudes, entre otras.\n",
    "\n",
    "En resumen, el web scraping es una técnica automatizada para la recopilación de datos de sitios web, que se utiliza comúnmente en diversas aplicaciones comerciales y de investigación. Permite la extracción de grandes cantidades de información de manera eficiente y automatizada, lo que lo hace especialmente útil para la toma de decisiones basada en datos.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.03001,
     "end_time": "2020-11-10T13:18:37.840723",
     "exception": false,
     "start_time": "2020-11-10T13:18:37.810713",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Caso práctico\n",
    "\n",
    "Este material expande el marco inicial de las técnicas de web scraping y aborda la temática en un contexto del análisis y resolución de un caso práctico de análisis de sentimientos con Python. Tiene por objetivo analizar la aplicabilidad de los métodos de web scraping para el análisis de sentimientos usando como referencia las 9 etapas del ciclo de vida del Big Data.\n",
    "\n",
    "**Que revisaremos?**\n",
    "* Cómo usar web scraping para obtener reseñas de películas de IMDB\n",
    "* Cómo limpiar los datos\n",
    "* Qué es el Análisis de Sentimientos\n",
    "* Cómo usar técnicas de procesamiento del lenguaje natural (NLP)\n",
    "\n",
    "💡 _**Nota**_: _Este material ha sido preparado por la **Universidad de las Américas - UDLA**. Parte del contenido ha sido adaptado a partir de material público liberado en [Kaggle](kaggle.com), [Datacamp](datacamp.com) y otros sitios web._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sobre la empresa\n",
    "\n",
    "El siguiente caso de negocio es tomado de **Internet Movie Database (IMDb, en español: Base de datos de películas en Internet)** es una base de datos en línea que en un principio almacena información relacionada con películas, y con el tiempo se transforma en la base de datos más grande del mundo donde se encuentran programas de televisión, eventos en vivo y difundidos en televisión o en la web, entrega de premios y especiales. Se encuentra el personal de equipo de producción (incluyendo directores y productores), actores, series y programas de televisión, videojuegos, actores de doblaje y personajes ficticios que aparecen en los medios de entretenimiento visual. Recibe más de 100 millones de usuarios únicos al mes y cuenta con una versión móvil. IMDb fue inaugurada el 17 de octubre de 1985 y en 1998 fue adquirida por [Amazon](https://www.amazon.com).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.03001,
     "end_time": "2020-11-10T13:18:37.840723",
     "exception": false,
     "start_time": "2020-11-10T13:18:37.810713",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Evaluación de necesidades del negocio\n",
    "La fase de evaluación del caso de negocio requiere que se cree, evalúe y apruebe un caso de negocio antes de proceder a las tareas reales de análisis práctico.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En 1996, **IMDb** se constituyó como empresa en el Reino Unido, con el nombre de The Internet Movie Database Ltd. El fundador, Col Needham, se convirtió en el propietario primario así como en su imagen principal. IMDb se convirtió en un servicio patrocinado y financiado con publicidad. El debut empresarial se acompañó de nuevas secciones y una reescritura y optimización del sitio web.\n",
    "\n",
    "Los antecedentes de **IMDb** se remontan a 1989, cuando un aficionado publicó una discusión en un grupo de noticias en usenet sobre actrices atractivas. A partir de ese momento, otros usuarios de la lista comenzaron a recopilar actores y actrices con las películas en las que habían intervenido. La base de datos original fue construida a partir de las listas de créditos que Col Needham y otros dos lectores, Dave Knight y Andy Krieg, habían comenzado a publicar en el grupo. Needham publicó en septiembre de 1991 la primera herramienta simple (una serie de shell scripts de Unix) que permitía la consulta de las listas existentes en ese momento: la lista de directores, la de actores, la de actrices y la de actores fallecidos. La fusión de las cuatro la base de datos resultante se convertiría finalmente en la **IMDb**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.03001,
     "end_time": "2020-11-10T13:18:37.840723",
     "exception": false,
     "start_time": "2020-11-10T13:18:37.810713",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3. Adquisición y filtrado de datos\n",
    "Durante la etapa de adquisición y filtrado de datos se recopilan los datos de todas las fuentes de datos que se identificaron durante la etapa Identificación de datos.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.03001,
     "end_time": "2020-11-10T13:18:37.840723",
     "exception": false,
     "start_time": "2020-11-10T13:18:37.810713",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Dataset** \n",
    "\n",
    "Este conjunto de datos contiene las reseñas de películas de **IMDb**. Se trata de un conjunto de datos para la clasificación binaria (comentarios positivos y negativos) de sentimientos y contiene alrededor de 4.000 críticas de películas muy populares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.03001,
     "end_time": "2020-11-10T13:18:37.840723",
     "exception": false,
     "start_time": "2020-11-10T13:18:37.810713",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Diccionario de datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `Movie_ID`: Id de la pelicula.\n",
    "* `Review`: Reseña película.\n",
    "* `Rating`: Calificación de la pelicula."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.03001,
     "end_time": "2020-11-10T13:18:37.840723",
     "exception": false,
     "start_time": "2020-11-10T13:18:37.810713",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. Extracción de datos\n",
    "Durante esta etapa se debe extraer datos dispares y transformarlos en un formato que pueda facilitar el análisis de datos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.035782,
     "end_time": "2020-11-10T13:18:38.409834",
     "exception": false,
     "start_time": "2020-11-10T13:18:38.374052",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "El \"scraper\" primero hace clic en el botón para cargar todas las reseñas. Cuando carga todas las reseñas, busca los elementos de reseña y valoración, los almacena en una cadena y la añade a la lista. Más tarde convertimos la lista en un marco de datos y lo guardamos en formato csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importar librerías y módulos específicos de librerías**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.044555,
     "end_time": "2020-11-10T13:18:37.915836",
     "exception": false,
     "start_time": "2020-11-10T13:18:37.871281",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cargar el dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/vhteran/UDLA_Big_Data_aplicada_a_los_Negocios/main/data/get_out_cleaned.csv\"\n",
    "df = pd.read_csv(url, sep = \";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.03001,
     "end_time": "2020-11-10T13:18:37.840723",
     "exception": false,
     "start_time": "2020-11-10T13:18:37.810713",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5. Validación y limpieza de datos\n",
    "Los datos no válidos pueden sesgar y falsear los resultados de los análisis. La etapa de validación y depuración de datos se enfoca en establecer reglas de validación a menudo complejas y a eliminar cualquier dato no válido conocido.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>,Movie_ID,Review,Rating,Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1,1,\" interesting movie about an interracial c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the idea is original and interesting the actin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the movie has its share of racism that cant go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>out of  found this helpful was this review he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>permalink\",positive,9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4205</th>\n",
       "      <td>out of  found this helpful was this review he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4206</th>\n",
       "      <td>permalink\",positive,6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4207</th>\n",
       "      <td>1527,1527,\" i like how different yet compellin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4208</th>\n",
       "      <td>out of  found this helpful was this review he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4209</th>\n",
       "      <td>permalink\",positive,6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4210 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           ,Movie_ID,Review,Rating,Rate\n",
       "0     1,1,\" interesting movie about an interracial c...\n",
       "1     the idea is original and interesting the actin...\n",
       "2     the movie has its share of racism that cant go...\n",
       "3      out of  found this helpful was this review he...\n",
       "4                                 permalink\",positive,9\n",
       "...                                                 ...\n",
       "4205   out of  found this helpful was this review he...\n",
       "4206                              permalink\",positive,6\n",
       "4207  1527,1527,\" i like how different yet compellin...\n",
       "4208   out of  found this helpful was this review he...\n",
       "4209                              permalink\",positive,6\n",
       "\n",
       "[4210 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualizamos el dataset\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.032081,
     "end_time": "2020-11-10T13:18:38.641806",
     "exception": false,
     "start_time": "2020-11-10T13:18:38.609725",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "En primer lugar, debemos cambiar el nombre de la columna \"Sin nombre: 0\" a \"Movie_ID\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T13:18:38.713410Z",
     "iopub.status.busy": "2020-11-10T13:18:38.712266Z",
     "iopub.status.idle": "2020-11-10T13:18:38.715855Z",
     "shell.execute_reply": "2020-11-10T13:18:38.715175Z"
    },
    "papermill": {
     "duration": 0.041841,
     "end_time": "2020-11-10T13:18:38.715977",
     "exception": false,
     "start_time": "2020-11-10T13:18:38.674136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.rename(columns={\"Unnamed: 0\" : \"Movie_ID\"},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.032748,
     "end_time": "2020-11-10T13:18:38.781146",
     "exception": false,
     "start_time": "2020-11-10T13:18:38.748398",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "Ahora, dividiremos la columna \"Valoración\" en \"|\" y almacenaremos la valoración en una nueva columna llamada \"Valoración\". Asi, la columna \"Valoración\" sólo tendrá el puntaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T13:18:38.866216Z",
     "iopub.status.busy": "2020-11-10T13:18:38.865315Z",
     "iopub.status.idle": "2020-11-10T13:18:38.868813Z",
     "shell.execute_reply": "2020-11-10T13:18:38.869588Z"
    },
    "papermill": {
     "duration": 0.055117,
     "end_time": "2020-11-10T13:18:38.869783",
     "exception": false,
     "start_time": "2020-11-10T13:18:38.814666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Review'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Review'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRating\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mReview\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m      2\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReview\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReview\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Review'"
     ]
    }
   ],
   "source": [
    "df[\"Rating\"] = df[\"Review\"].apply(lambda x: x.split(\"|\")[0])\n",
    "df[\"Review\"] = df[\"Review\"].apply(lambda x: x.split(\"|\")[1])\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.032727,
     "end_time": "2020-11-10T13:18:38.936186",
     "exception": false,
     "start_time": "2020-11-10T13:18:38.903459",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Ahora nos centraremos en limpiar las columnas de \"Revisión\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T13:18:39.020372Z",
     "iopub.status.busy": "2020-11-10T13:18:39.019546Z",
     "iopub.status.idle": "2020-11-10T13:18:39.182996Z",
     "shell.execute_reply": "2020-11-10T13:18:39.182208Z"
    },
    "papermill": {
     "duration": 0.213498,
     "end_time": "2020-11-10T13:18:39.183119",
     "exception": false,
     "start_time": "2020-11-10T13:18:38.969621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Review'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Review'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mReview\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m, np\u001b[38;5;241m.\u001b[39mnan, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m# replacing space with nan\u001b[39;00m\n\u001b[0;32m      3\u001b[0m df\u001b[38;5;241m.\u001b[39mdropna(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m#drop nan values, coz some of review didn't have actual review\u001b[39;00m\n\u001b[0;32m      4\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReview\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReview\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;66;03m# Converting everything to lower coz \"Movie\" and \"movie\" is not the same thing\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Review'"
     ]
    }
   ],
   "source": [
    "df['Review'].replace(\" \", np.nan, inplace=True) # replacing space with nan\n",
    "\n",
    "df.dropna(inplace=True) #drop nan values, coz some of review didn't have actual review\n",
    "df[\"Review\"] = df[\"Review\"].str.lower() # Converting everything to lower coz \"Movie\" and \"movie\" is not the same thing\n",
    "\n",
    "# Removing special characters from Reviews\n",
    "spec_chars = [\"±\",\"@\",\"#\",\"$\",\"%\",\"^\",\n",
    "                 \"&\",\"*\",\"(\",\")\",\"_\",\"+\",\"=\",\n",
    "                 \"-\",\"/\",\">\",\"<\",\"?\",\n",
    "                 \"~\",\"`\",\"'\",\"[\",\"]\",\"|\",\"}\",\n",
    "                 \"{\",'\"', \".\",\",\",\"!\",\";\"]\n",
    "\n",
    "for char in spec_chars:\n",
    "    df[\"Review\"] = df[\"Review\"].str.replace(char, \"\")\n",
    "\n",
    "df[\"Review\"].apply(lambda x: x.encode('ascii', 'ignore').decode('ascii')) # getting rid of emojis\n",
    "\n",
    "df['Review'] = df['Review'].str.replace('\\d+', '') # Remove numbers from Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.033145,
     "end_time": "2020-11-10T13:18:39.250233",
     "exception": false,
     "start_time": "2020-11-10T13:18:39.217088",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Ha llegado el momento de convertir la columna de críticas en críticas Positivas y Negativas. Nos desharemos de la barra y del número diez. Así, \"N/10\" queremos guardar la N porque en realidad es la valoración dejada por el usuario. A continuación convertiremos la columna en numérica y utilizaremos el bucle for para convertir las valoraciones menores de 5 en negativas y las mayores o iguales de 5 en positivas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": false,
    "execution": {
     "iopub.execute_input": "2020-11-10T13:18:39.330085Z",
     "iopub.status.busy": "2020-11-10T13:18:39.329104Z",
     "iopub.status.idle": "2020-11-10T13:18:39.951209Z",
     "shell.execute_reply": "2020-11-10T13:18:39.950429Z"
    },
    "papermill": {
     "duration": 0.667893,
     "end_time": "2020-11-10T13:18:39.951380",
     "exception": false,
     "start_time": "2020-11-10T13:18:39.283487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"Rate\"] = df[\"Rating\"].apply(lambda x: x.split(\"/\")[0])\n",
    "df[\"Rate\"] = pd.to_numeric(df[\"Rate\"])\n",
    "\n",
    "for i in range(len(df)):\n",
    "    if (df[\"Rate\"].iloc[i] < 5):\n",
    "        df[\"Rating\"].iloc[i] = \"negative\"\n",
    "    else:\n",
    "        df[\"Rating\"].iloc[i] = \"positive\"\n",
    "        \n",
    "df.to_csv(\"get_out_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.03001,
     "end_time": "2020-11-10T13:18:37.840723",
     "exception": false,
     "start_time": "2020-11-10T13:18:37.810713",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 6. Agregación y representación de datos\n",
    "La etapa de agregación y representación de datos, se dedica a integrar múltiples conjuntos de datos para obtener una visión unificada.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.03001,
     "end_time": "2020-11-10T13:18:37.840723",
     "exception": false,
     "start_time": "2020-11-10T13:18:37.810713",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Este caso de uso no requiere la integración de otros datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.03001,
     "end_time": "2020-11-10T13:18:37.840723",
     "exception": false,
     "start_time": "2020-11-10T13:18:37.810713",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 7. Análisis de datos\n",
    "La etapa de análisis de datos se enfoca en llevar a cabo la tarea de análisis propiamente dicha, que suele implicar uno o más tipos de análisis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.033562,
     "end_time": "2020-11-10T13:18:40.019067",
     "exception": false,
     "start_time": "2020-11-10T13:18:39.985505",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <a id='Sentiment-Analysis' style=\"color:black\">**Análisis de Sentimientos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.033514,
     "end_time": "2020-11-10T13:18:40.154361",
     "exception": false,
     "start_time": "2020-11-10T13:18:40.120847",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "El sistema de análisis de sentimientos para el análisis de textos combina técnicas de procesamiento del lenguaje natural (PLN) y de aprendizaje automático para asignar puntuaciones ponderadas de sentimientos a las entidades, temas y categorías de una frase u oración. Utilizar el análisis de sentimientos podría ayudarle a descubrir si los clientes están satisfechos con sus planes de precios, su servicio de atención al cliente, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.033453,
     "end_time": "2020-11-10T13:18:40.221678",
     "exception": false,
     "start_time": "2020-11-10T13:18:40.188225",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Importemos las bibliotecas y carguemos el marco de datos limpiado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T13:18:40.299790Z",
     "iopub.status.busy": "2020-11-10T13:18:40.298983Z",
     "iopub.status.idle": "2020-11-10T13:18:42.329099Z",
     "shell.execute_reply": "2020-11-10T13:18:42.328107Z"
    },
    "papermill": {
     "duration": 2.07381,
     "end_time": "2020-11-10T13:18:42.329267",
     "exception": false,
     "start_time": "2020-11-10T13:18:40.255457",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "df = pd.read_csv('/kaggle/input/movies/get_out_cleaned.csv')\n",
    "df.drop(columns=[\"Unnamed: 0\"],inplace=True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.03423,
     "end_time": "2020-11-10T13:18:42.398994",
     "exception": false,
     "start_time": "2020-11-10T13:18:42.364764",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    " <a id='Tokenization' style=\"color:black\">**Tokenización**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.034533,
     "end_time": "2020-11-10T13:18:42.468399",
     "exception": false,
     "start_time": "2020-11-10T13:18:42.433866",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**La tokenización** es el proceso de convertir texto en tokens antes de transformarlo en vectores. También es más fácil filtrar los tokens innecesarios. Por ejemplo, un documento en párrafos o frases en palabras. En este caso estamos tokenizando las reseñas en palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T13:18:42.554097Z",
     "iopub.status.busy": "2020-11-10T13:18:42.553333Z",
     "iopub.status.idle": "2020-11-10T13:18:44.370713Z",
     "shell.execute_reply": "2020-11-10T13:18:44.370026Z"
    },
    "papermill": {
     "duration": 1.867647,
     "end_time": "2020-11-10T13:18:44.370872",
     "exception": false,
     "start_time": "2020-11-10T13:18:42.503225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) # eng stopwords\n",
    "df['tokenized_reviews'] = df.apply(lambda row: word_tokenize(row['Review']), axis=1) # Tokenization of reviews\n",
    "df[\"filtered\"] = df['tokenized_reviews'].apply(lambda x: [item for item in x if item not in stop_words]) #Removing stopwrods from tokenized data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.038557,
     "end_time": "2020-11-10T13:18:44.444498",
     "exception": false,
     "start_time": "2020-11-10T13:18:44.405941",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id='Count-Vectorizer' style=\"color:black\">**Vectorizador de conteo**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.034483,
     "end_time": "2020-11-10T13:18:44.513725",
     "exception": false,
     "start_time": "2020-11-10T13:18:44.479242",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "El **CountVectorizer** se utiliza para convertir una colección de documentos de texto en un vector de recuentos de términos/tokens.\n",
    "\n",
    "Por ejemplo words=[\"movie\", \"good\", \"perfect, \"good\"] se transformaría en: \"película\" = 1, \"bueno\" = 2, \"perfecto\" = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.249821,
     "end_time": "2020-11-10T13:18:44.799058",
     "exception": false,
     "start_time": "2020-11-10T13:18:44.549237",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['filtered']=df['filtered'].apply(str)\n",
    "cv = CountVectorizer(lowercase=False,stop_words='english',binary=True)\n",
    "cv.fit(df[\"filtered\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.035183,
     "end_time": "2020-11-10T13:18:44.869700",
     "exception": false,
     "start_time": "2020-11-10T13:18:44.834517",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Inicialicemos nuestra característica y objetivo y hagamos la división de prueba de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T13:18:44.990277Z",
     "iopub.status.busy": "2020-11-10T13:18:44.969381Z",
     "iopub.status.idle": "2020-11-10T13:18:45.100821Z",
     "shell.execute_reply": "2020-11-10T13:18:45.100084Z"
    },
    "papermill": {
     "duration": 0.196145,
     "end_time": "2020-11-10T13:18:45.100961",
     "exception": false,
     "start_time": "2020-11-10T13:18:44.904816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = cv.transform(df[\"filtered\"])\n",
    "y = df[\"Rating\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.03001,
     "end_time": "2020-11-10T13:18:37.840723",
     "exception": false,
     "start_time": "2020-11-10T13:18:37.810713",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 8. Visualización de datos\n",
    "La capacidad de analizar grandes cantidades de datos y obtener información útil tiene poco valor si los únicos que pueden interpretar los resultados son los analistas.\n",
    "La etapa de visualización de datos se dedica a utilizar técnicas y herramientas de visualización de datos para comunicar gráficamente los resultados del análisis con vistas a una interpretación eficaz por parte de los usuarios empresariales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.036798,
     "end_time": "2020-11-10T13:18:45.552186",
     "exception": false,
     "start_time": "2020-11-10T13:18:45.515388",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <a id='KNN' style=\"color:black\">**KNN(K-Nearest-Neighbor)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.036224,
     "end_time": "2020-11-10T13:18:45.624670",
     "exception": false,
     "start_time": "2020-11-10T13:18:45.588446",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "K-Nearest-Neighbor es un algoritmo basado en instancia de tipo supervisado de Machine Learning. Puede usarse para clasificar nuevas muestras (valores discretos) o para predecir (regresión, valores continuos). Al ser un método sencillo, es ideal para introducirse en el mundo del  Aprendizaje Automático. Sirve esencialmente para clasificar valores buscando los puntos de datos “más similares” (por cercanía) aprendidos en la etapa de entrenamiento (ver 7 pasos para crear tu ML) y haciendo conjeturas de nuevos puntos basado en esa clasificación.\n",
    "\n",
    "Es un método que simplemente busca en las observaciones más cercanas a la que se está tratando de predecir y clasifica el punto de interés basado en la mayoría de datos que le rodean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.036224,
     "end_time": "2020-11-10T13:18:45.624670",
     "exception": false,
     "start_time": "2020-11-10T13:18:45.588446",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "Elegimos el mejor valor K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T13:18:45.707612Z",
     "iopub.status.busy": "2020-11-10T13:18:45.706801Z",
     "iopub.status.idle": "2020-11-10T13:18:50.323625Z",
     "shell.execute_reply": "2020-11-10T13:18:50.322791Z"
    },
    "papermill": {
     "duration": 4.662293,
     "end_time": "2020-11-10T13:18:50.323786",
     "exception": false,
     "start_time": "2020-11-10T13:18:45.661493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "errors = []\n",
    "for k in range(1,100):\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    model.fit(X_train,y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    errors.append(np.mean(pred!=y_test))\n",
    "plt.plot(range(1,100),errors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T13:18:50.424735Z",
     "iopub.status.busy": "2020-11-10T13:18:50.423821Z",
     "iopub.status.idle": "2020-11-10T13:18:50.473698Z",
     "shell.execute_reply": "2020-11-10T13:18:50.472881Z"
    },
    "papermill": {
     "duration": 0.108178,
     "end_time": "2020-11-10T13:18:50.473829",
     "exception": false,
     "start_time": "2020-11-10T13:18:50.365651",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=25)\n",
    "knn.fit(X_train,y_train)\n",
    "print(\"K-Nearest Neighbours accuracy score: {}\".format(accuracy_score(y_test, knn.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.042796,
     "end_time": "2020-11-10T13:18:50.559717",
     "exception": false,
     "start_time": "2020-11-10T13:18:50.516921",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <a id='Multinomial-Naive-Bayes' style=\"color:black\">**Naive Bayes Multinomial**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T13:18:50.651343Z",
     "iopub.status.busy": "2020-11-10T13:18:50.650111Z",
     "iopub.status.idle": "2020-11-10T13:18:50.659246Z",
     "shell.execute_reply": "2020-11-10T13:18:50.658177Z"
    },
    "papermill": {
     "duration": 0.056676,
     "end_time": "2020-11-10T13:18:50.659442",
     "exception": false,
     "start_time": "2020-11-10T13:18:50.602766",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MNB = MultinomialNB()\n",
    "MNB.fit(X_train,y_train)\n",
    "print(\"Multinomial Naive Bayes accuracy score: {}\".format(accuracy_score(y_test, MNB.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.038483,
     "end_time": "2020-11-10T13:18:50.911219",
     "exception": false,
     "start_time": "2020-11-10T13:18:50.872736",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <a id='Word-Cloud' style=\"color:black\">**Nube de palabras**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.038326,
     "end_time": "2020-11-10T13:18:50.988421",
     "exception": false,
     "start_time": "2020-11-10T13:18:50.950095",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Una nube de palabras es una representación visual de datos textuales. Muestra una lista de palabras, la importancia de cada una se muestra con el tamaño de la fuente o el color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T13:18:51.077105Z",
     "iopub.status.busy": "2020-11-10T13:18:51.076280Z",
     "iopub.status.idle": "2020-11-10T13:18:54.220503Z",
     "shell.execute_reply": "2020-11-10T13:18:54.221574Z"
    },
    "papermill": {
     "duration": 3.194902,
     "end_time": "2020-11-10T13:18:54.221827",
     "exception": false,
     "start_time": "2020-11-10T13:18:51.026925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "stopwords = set(STOPWORDS)\n",
    "wordcloud = WordCloud(width = 800, height = 800,\n",
    "                      background_color ='white',\n",
    "                      stopwords = stopwords,\n",
    "                      min_font_size = 10).generate(' '.join(df['filtered']))\n",
    "\n",
    "plt.figure(figsize = (8, 8), facecolor = None)\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.03001,
     "end_time": "2020-11-10T13:18:37.840723",
     "exception": false,
     "start_time": "2020-11-10T13:18:37.810713",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 9. Utilización de los resultados del análisis\n",
    "Después de que los resultados del análisis se pongan a disposición de los usuarios de negocio para apoyar la toma de decisiones empresariales, por ejemplo a través de cuadros de mando o paneles, puede haber más oportunidades para utilizar los resultados del análisis. La etapa de utilización de los resultados del análisis, esta enfocada en determinar cómo y dónde se pueden aprovechar más los datos del análisis procesado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.047014,
     "end_time": "2020-11-10T13:18:54.319148",
     "exception": false,
     "start_time": "2020-11-10T13:18:54.272134",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id='Conclusion' style=\"color:black\">**Conclusiones**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.052865,
     "end_time": "2020-11-10T13:18:54.420501",
     "exception": false,
     "start_time": "2020-11-10T13:18:54.367636",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- Los modelos, con una precisión media del 78% en un conjunto de datos de unos 1.600, demostraron ser mejores. El modelo funcionaría aún mejor en un conjunto de datos mayor.\n",
    "\n",
    "- Este proyecto puede mejorarse añadiendo XGBoost, ¡y también sería interesante probar TextBlob!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "papermill": {
   "duration": 23.133858,
   "end_time": "2020-11-10T13:18:55.547544",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-10T13:18:32.413686",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
